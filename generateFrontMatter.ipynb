{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "faced-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "sacred-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "proceeding_ID_Paper = \"12780\"\n",
    "proceeding_ID_EA = \"12781\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "developing-indiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>File</th>\n",
       "      <th>NameCommittee</th>\n",
       "      <th>NameReviewers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paper</td>\n",
       "      <td>paper</td>\n",
       "      <td>tp23a</td>\n",
       "      <td>Associated Chairs</td>\n",
       "      <td>Reviewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Late-Breaking Work</td>\n",
       "      <td>lbw</td>\n",
       "      <td>tp23k</td>\n",
       "      <td>Associated Chairs</td>\n",
       "      <td>Reviewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Demonstrations</td>\n",
       "      <td>demo</td>\n",
       "      <td>tp23o</td>\n",
       "      <td>Jury Member</td>\n",
       "      <td>Reviewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doctoral Consortium</td>\n",
       "      <td>dc</td>\n",
       "      <td>tp23j</td>\n",
       "      <td>Jury Member</td>\n",
       "      <td>Reviewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Workshop</td>\n",
       "      <td>ws</td>\n",
       "      <td>tp23d</td>\n",
       "      <td>Jury Member</td>\n",
       "      <td>Reviewers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name   Code   File      NameCommittee NameReviewers\n",
       "0                Paper  paper  tp23a  Associated Chairs     Reviewers\n",
       "1   Late-Breaking Work    lbw  tp23k  Associated Chairs     Reviewers\n",
       "2       Demonstrations   demo  tp23o        Jury Member     Reviewers\n",
       "3  Doctoral Consortium     dc  tp23j        Jury Member     Reviewers\n",
       "4             Workshop     ws  tp23d        Jury Member     Reviewers"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VENUE = \"tp23\"\n",
    "setup = [[\"Paper\", \"paper\", \"tp23a\", \"Associated Chairs\",\"Reviewers\"],\n",
    "         [\"Late-Breaking Work\", \"lbw\", \"tp23k\", \"Associated Chairs\", \"Reviewers\"],\n",
    "         [\"Demonstrations\", \"demo\", \"tp23o\", \"Jury Member\", \"Reviewers\"],\n",
    "         [\"Doctoral Consortium\", \"dc\", \"tp23j\", \"Jury Member\", \"Reviewers\"],\n",
    "         [\"Workshop\", \"ws\", \"tp23d\", \"Jury Member\", \"Reviewers\"],\n",
    "        ]\n",
    "\n",
    "dfVenues = pd.DataFrame(setup, columns=[\"Name\", \"Code\", \"File\", \"NameCommittee\", \"NameReviewers\"])\n",
    "dfVenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "transparent-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"tp23k\"\n",
    "\n",
    "vanues = {\"e\":\"src\", \"f\":\"sdc\", \"g\":\"sgc\", \"h\":\"lbw\", \"i\":\"ws\", \"j\":\"dc\", \"k\":\"dein\", \"l\":\"panel\", \"m\":\"cs\", \"n\":\"crs\", \"o\":\"altChi\", \"q\":\"sig\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "specific-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCommittee(venueCode):\n",
    "    path = f\"./data-PCS/{venueCode}_committee.csv\"\n",
    "    if (not os.path.isfile(path)):\n",
    "        print(f\"{venueCode} has no committee file\")\n",
    "        return []\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df[\"Reviews assigned\"] != 0]\n",
    "    \n",
    "    if (len(df) == 0):\n",
    "        print(f\"{venueCode} has no reviewers\")\n",
    "        return []\n",
    "\n",
    "    lstText = []\n",
    "    df[\"Family name\"] = df[\"Family name\"].str.title()\n",
    "    df[\"First name\"] = df[\"First name\"].str.title()\n",
    "    #df[\"Middle name\"] = df[\"Middle name\"].str.title()\n",
    "    df = df.sort_values([\"Family name\", \"First name\", \"Middle initial\"])\n",
    "\n",
    "    for i, e in df.iterrows():\n",
    "        for i in range (1,7):\n",
    "            if isinstance(e[f\"Affil {i} Institution\"], str):\n",
    "                break\n",
    "        aff = \"\"\n",
    "        if isinstance(e[f\"Affil {i} Institution\"], str):\n",
    "            aff = f'{e[f\"Affil {i} Institution\"]}, {e[f\"Affil {i} Country\"]}'\n",
    "\n",
    "        aff = aff.replace(\"&\", \"\\\\&\")\n",
    "        if isinstance(e[\"Middle initial\"], str):\n",
    "            lstText.append(f'{e[\"First name\"]} {e[\"Middle initial\"]} {e[\"Family name\"]}, \\\\emph{{{aff}}}\\\\\\\\')\n",
    "        else:\n",
    "            lstText.append(f'{e[\"First name\"]} {e[\"Family name\"]}, \\\\emph{{{aff}}}\\\\\\\\')\n",
    "\n",
    "    if (len(df) > 50):   \n",
    "        lstText.insert(0, \"\\\\begin{multicols}{2}\")\n",
    "        lstText.append(\"\\end{multicols}\")\n",
    "    else:\n",
    "        \n",
    "        lstText.insert(0, \"%\\\\begin{multicols}{2}\")\n",
    "        lstText.append(\"%\\end{multicols}\")\n",
    "    lstText.append(\"\")\n",
    "    return lstText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "understood-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReviews(venueCode):\n",
    "    path = f\"./data-PCS/{venueCode}_reviewers.csv\"\n",
    "    if (not os.path.isfile(path)):\n",
    "        print(f\"{venueCode} has no reviwer file\")\n",
    "        return []\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df[\"Reviews assigned\"] != 0]\n",
    "    \n",
    "    if (len(df) == 0):\n",
    "        print(f\"{venueCode} has no reviewers\")\n",
    "        return []\n",
    "    \n",
    "    # Ensure that all names start with a capital first latter.\n",
    "    df[\"Family name\"] = df[\"Family name\"].apply(lambda x: x[0].title()+x[1:] if len(x)>2 else x)\n",
    "    df[\"First name\"] = df[\"First name\"].apply(lambda x: x[0].title()+x[1:] if len(x)>2 else x)\n",
    "    if \"Middle name\"in df.columns:\n",
    "        df[\"Middle name\"] = df[\"Middle name\"].apply(lambda x: x[0].title()+x[1:] if len(x)>2 else x)\n",
    "    \n",
    "    df = df.sort_values([\"Family name\", \"First name\", \"Middle initial\"])\n",
    "    lstText = []\n",
    "    lstText.append(\"\\\\begin{multicols}{3}\")\n",
    "    for i, e in df.iterrows():\n",
    "        if isinstance(e[\"Middle initial\"], str):\n",
    "            lstText.append(f'{e[\"First name\"]} {e[\"Middle initial\"]} {e[\"Family name\"]}\\\\\\\\')\n",
    "        else:\n",
    "            lstText.append(f'{e[\"First name\"]} {e[\"Family name\"]}\\\\\\\\')\n",
    "    lstText.append(\"\\\\end{multicols}\")\n",
    "    lstText.append(\"\")\n",
    "    return lstText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "neural-syria",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp23o has no reviewers\n",
      "tp23j has no reviewers\n",
      "tp23d has no reviewers\n"
     ]
    }
   ],
   "source": [
    "for i, e in dfVenues.iterrows():\n",
    "    lstExport = []\n",
    "    lstExport.append(\"% If this venue/track has subcommittees, you might want to split the \\subsection{Committee Member} into different \\subsubsections for the different committees.\")\n",
    "    lstExport.append(\"\")    \n",
    "    lstExport.append(f\"\\\\subsection{{{e.Name} Chairs}}\")\n",
    "    lstExport.append(\"First Chair Full Name, \\emph{Affiliation, Country}\\\\\\\\\")\n",
    "    lstExport.append(\"Second Chair Full Name, \\emph{Affiliation, Country}\")\n",
    "    lstExport.append(\"\")\n",
    "    lstExport.append(f\"%\\subsection*{{Assistants to {e.Name} Chairs}}\")\n",
    "    lstExport.append(\"%First Assistants Full Name, \\emph{Affiliation}\\\\\\\\\")\n",
    "    lstExport.append(\"%Second Assistants Full Name, \\emph{Affiliation}\")\n",
    "    lstExport.append(\"\")\n",
    "    lstExport.append(\"\")\n",
    "    \n",
    "    commitee = getCommittee(e.File)\n",
    "    if (len(commitee) > 0):\n",
    "        lstExport.append(f\"\\subsection{{{e.NameCommittee}}}\")\n",
    "        lstExport.extend(commitee)\n",
    "\n",
    "    reviewers = getReviews(e.File)\n",
    "    if (len(reviewers) > 0):\n",
    "        lstExport.append(f\"\\subsection{{{e.NameReviewers}}}\")\n",
    "        lstExport.extend(reviewers)\n",
    "    \n",
    "    if (len(lstText) > 0):\n",
    "        with open(f'committee/committee-{e.Code}.tex', 'w') as fp:\n",
    "            fp.write('\\n'.join(lstExport))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-luther",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "flush-privilege",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'export_12781.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[234], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dfTAPS \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexport_12781.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m file1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproceeding_ID_EA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m lines \u001b[38;5;241m=\u001b[39m file1\u001b[38;5;241m.\u001b[39mreadlines()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'export_12781.csv'"
     ]
    }
   ],
   "source": [
    "dfTAPS = pd.read_csv(\"export_12781.csv\")\n",
    "\n",
    "file1 = open(f\"./{proceeding_ID_EA}.csv\", 'r')\n",
    "lines = file1.readlines()\n",
    "ids = []\n",
    "lstLines = []\n",
    "for x in lines[1:]:\n",
    "    e = x[1:].split('\",\"')\n",
    "\n",
    "    if (not(\"WITHDRAWN\" in x)):\n",
    "        lstLines.append(e)\n",
    "        ids.append(x.split(\",\")[0].replace('\"', \"\"))\n",
    "    else:\n",
    "        print(\"WITHDRAWN\", x.split(\",\")[0].replace('\"', \"\"))\n",
    "    \n",
    "\n",
    "dfACM = pd.DataFrame(lstLines)\n",
    "dfACM.columns = [\"ID\",\"Title\",\"Author\",\"EmailX\",\"DL Paper Type\",\"Rights Granted\",\"Third Party\",\"Aux. Material\",\"Video Recording\",\"Artistic Images\",\"Govt. Employees\",\"Open Access\",\"DOI\",\"Authorizer\",\"Statement\",\"CC License\",\"Non-ACM Copyright\"]\n",
    "dfACM['Email2'] = dfACM.EmailX.apply(lambda x: x.split(\" \")[0])\n",
    "dfACM['Signed'] = dfACM['Non-ACM Copyright'].apply(lambda x: x[:-3]) != \"load For\"\n",
    "dfACM[\"TitleOld\"] = dfACM.Title\n",
    "dfACM.Title = dfACM.TitleOld.apply(lambda x: x.split(\" \\\\setcopyright{\")[0])\n",
    "dfACM[\"VenueShort\"] = dfACM.ID.apply(lambda x: re.sub(r'[0-9]', '', x))\n",
    "\n",
    "dfACM[\"TitleRaw\"] = dfACM.Title.str.replace('\"', '')\n",
    "dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace('[', '', regex=False)\n",
    "dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.lower()\n",
    "print(dfACM[\"TitleRaw\"].apply(lambda x: x[0]).unique())\n",
    "\n",
    "dictVenue = {'pn':\"Paper\",\n",
    "    'ws':\"Workshops / Symposia\",\n",
    "    'cs':'Case Studies of HCI in Practice',\n",
    "    'crs':'Courses',\n",
    "    'dc':'Doctoral Consortium',\n",
    "    'alt': 'alt.chi',\n",
    "    'sig': 'Special Interest Groups',\n",
    "    'panel': 'Panels',\n",
    "    'sgc': 'Student Game Competition',\n",
    "    'sdc': 'Student Design Competition',\n",
    "    'dein': 'Interactivity',\n",
    "    'int': 'Interactivity',\n",
    "    'src': 'Student Research Competition',\n",
    "    'lbw': 'Late-Breaking Work'}\n",
    "\n",
    "dfACM.VenueShort = dfACM.VenueShort.str.replace(\"dein\", \"int\")\n",
    "\n",
    "dfACM[\"VenueName\"] = dfACM.VenueShort.map(dictVenue)\n",
    "\n",
    "myOrder = CategoricalDtype(\n",
    "    ['pn', 'lbw', 'ws', 'cs', 'alt', 'dein', 'int', 'dc', 'sig', 'panel', 'crs',  'src', 'sdc', 'sgc'], \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "dfACM = dfACM.drop_duplicates(\"ID\")\n",
    "\n",
    "df = dfACM\n",
    "\n",
    "print(len(df))\n",
    "df = pd.merge(df, dfTAPS[[\"ID\", \"PaperID\"]], left_on=\"ID\", right_on=\"ID\")\n",
    "print(len(df))\n",
    "\n",
    "df.VenueShort = df.VenueShort.astype(myOrder)\n",
    "df = df.sort_values([\"VenueShort\", \"TitleRaw\"])\n",
    "\n",
    "text = []\n",
    "lastVenueShort = \"\"\n",
    "counter = 1\n",
    "counterTOC = 1\n",
    "\n",
    "tapsTOC=[]\n",
    "lstAuthorIndex = []\n",
    "for i, e in df.iterrows():\n",
    "    if (e.VenueShort != lastVenueShort):\n",
    "        \n",
    "        if counter != 1:\n",
    "            text.append(f'\\\\end{{enumerate}}')\n",
    "            text.append(\"\")\n",
    "            \n",
    "        text.append(f'\\\\subsection{{{e.VenueName}}}')\n",
    "        text.append(\"\")\n",
    "        text.append(f'\\\\begin{{enumerate}}')\n",
    "        \n",
    "        \n",
    "        lastVenueShort = e.VenueShort\n",
    "        counter = 1\n",
    "    \n",
    "    \n",
    "    TOC_ID = f\"{e.VenueShort.upper()}{counter:03}\"\n",
    "    text.append(f'\\\\item[\\\\href{{{e.DOI}}}{{\\\\textbf{{{TOC_ID}}}}}]')\n",
    "    \n",
    "    xx =f'\\\\href{{{e.DOI}}}{{\\\\textbf{{{e.Title}}}}}\\\\\\\\'\n",
    "    text.append(xx.replace(\"&\", \"\\\\&\").replace(\"#\", \"\\\\#\"))\n",
    "    for x in e.Author.split(\";\"):\n",
    "        x = x.split(\":\")\n",
    "        xx = f\"{x[0]} \\\\emph{{({x[1]})}} \\\\\\\\\"\n",
    "        lstAuthorIndex.append([x[0], TOC_ID])\n",
    "        text.append(xx.replace(\"&\", \"\\\\&\").replace(\"#\", \"\\\\#\").replace(\",\", \", \").replace(\"  \", \" \"))\n",
    "    \n",
    "    text.append(\"\")\n",
    "    \n",
    "    \n",
    "    tapsTOC.append([counterTOC, e.PaperID, e.ID, TOC_ID, e.Title, e.VenueName])\n",
    "    counter = counter + 1\n",
    "    counterTOC = counterTOC + 1\n",
    "\n",
    "text.append(f'\\\\end{{enumerate}}')\n",
    "\n",
    "if (len(text) > 0):\n",
    "    with open(f'./content/content-ea.tex', 'w') as fp:\n",
    "        fp.write('\\n'.join(text))\n",
    "        \n",
    "        \n",
    "\n",
    "with open('./TOC-CHIEA23.csv', 'w', newline='') as csvfile:\n",
    "    w = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='\"')\n",
    "    w.writerow([\"ID\",\"PaperID\",\"PCS_ID\",\"TOC_ID\",\"Title\",\"Session\"])\n",
    "    for e in tapsTOC:\n",
    "        w.writerow(e)\n",
    "        \n",
    "        \n",
    "dfAI = pd.DataFrame(lstAuthorIndex)\n",
    "dfAI.columns = [\"Name\", \"Submission\"]\n",
    "dfAI = dfAI.groupby(\"Name\").Submission.apply(lambda x: \", \".join(x))\n",
    "dfAI = dfAI.reset_index()\n",
    "dfAI[\"NameRaw\"] = dfAI.Name.str.replace('\"', '')\n",
    "dfAI[\"NameRaw\"] = dfAI.NameRaw.apply(lambda x: unidecode(x))\n",
    "dfAI[\"NameRaw\"] = dfAI.NameRaw.str.replace('[', '', regex=False)\n",
    "dfAI[\"NameRaw\"] = dfAI.NameRaw.str.lower()\n",
    "dfAI = dfAI.sort_values(\"NameRaw\")\n",
    "\n",
    "if (len(dfAI) > 0):\n",
    "    with open(f'./content/index-ea.tex', 'w') as fp:\n",
    "        fp.write('\\\\begin{multicols}{2}\\n')\n",
    "        for i, e in dfAI.iterrows():\n",
    "            fp.write(f'{e.Name} \\dotfill {e.Submission}\\\\\\\\\\n')\n",
    "            \n",
    "        fp.write('\\\\end{multicols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "informational-think",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              aale luusua\n",
       "1       aarnout brombacher\n",
       "2          aaron j quigley\n",
       "3               aaron lyon\n",
       "4           aaron schecter\n",
       "               ...        \n",
       "2354      zinaida benenson\n",
       "2355               ziru li\n",
       "2356          ziyuan jiang\n",
       "2357     zjenja doubrovski\n",
       "2358        zoya bylinskii\n",
       "Name: NameRaw, Length: 2360, dtype: object"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAI.NameRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "round-interpretation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late-Breaking Work\n",
      "Workshops / Symposia\n",
      "Case Studies of HCI in Practice\n",
      "alt.chi\n",
      "Interactivity\n",
      "Doctoral Consortium\n",
      "Special Interest Groups\n",
      "Panels\n",
      "Courses\n",
      "Student Research Competition\n",
      "Student Design Competition\n",
      "Student Game Competition\n"
     ]
    }
   ],
   "source": [
    "lastVenueShort = \"\"\n",
    "for i, e in df.iterrows():\n",
    "    if (e.VenueShort != lastVenueShort):\n",
    "        print(e.VenueName)\n",
    "        lastVenueShort = e.VenueShort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "parliamentary-brand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in 0 papers\n",
      "WITHDRAWN pn8949\n",
      "WITHDRAWN pn6732\n",
      "['i' 'e' 'p' 'm' 'd' 'u' 'a' 'j' 'f' 's' 'r' 't' 'h' 'b' 'w' 'g' 'v' 'c'\n",
      " 'µ' 'n' 'l' 'o' 'q' '3' 'y' 'k' '1' 'z' '4' 'x']\n",
      "883\n",
      "879\n",
      "879\n"
     ]
    }
   ],
   "source": [
    "dfTAPS = pd.read_csv(\"export_12780.csv\")\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"qoala-chi23.json\", 'r') as f:\n",
    "    qoala = json.load(f)\n",
    "    \n",
    "dfQPapers = pd.DataFrame(qoala[\"contents\"])\n",
    "dfQPapers = dfQPapers[dfQPapers.importedId.apply(lambda x: x.startswith(\"chi23b\"))]\n",
    "print(f'Error in {len(dfQPapers[dfQPapers.sessionIds.apply(lambda x: len(x) > 1)])} papers')\n",
    "dfQPapers.sessionIds = dfQPapers.sessionIds.apply(lambda x: x[0])\n",
    "\n",
    "dfQSessions = pd.DataFrame(qoala[\"sessions\"])\n",
    "dfQSessions = dfQSessions.rename(columns={\"id\":\"sessionId\", \"name\":\"SessionName\"})\n",
    "\n",
    "dfQ = pd.merge(dfQPapers, dfQSessions[[\"sessionId\", \"SessionName\"]], left_on=\"sessionIds\", right_on=\"sessionId\", how=\"left\")[[\"importedId\", \"title\", \"SessionName\"]]\n",
    "\n",
    "dfQ[\"ID\"] = dfQ.importedId.apply(lambda x: x.replace(\"chi23b-\", \"pn\"))\n",
    "dfQ\n",
    "\n",
    "\n",
    "file1 = open(f\"./{proceeding_ID_Paper}.csv\", 'r')\n",
    "lines = file1.readlines()\n",
    "ids = []\n",
    "lstLines = []\n",
    "for x in lines[1:]:\n",
    "    e = x[1:].split('\",\"')\n",
    "\n",
    "    if (not(\"WITHDRAWN\" in x)):\n",
    "        lstLines.append(e)\n",
    "        ids.append(x.split(\",\")[0].replace('\"', \"\"))\n",
    "    else:\n",
    "        print(\"WITHDRAWN\", x.split(\",\")[0].replace('\"', \"\"))\n",
    "    \n",
    "\n",
    "dfACM = pd.DataFrame(lstLines)\n",
    "dfACM.columns = [\"ID\",\"Title\",\"Author\",\"EmailX\",\"DL Paper Type\",\"Rights Granted\",\"Third Party\",\"Aux. Material\",\"Video Recording\",\"Artistic Images\",\"Govt. Employees\",\"Open Access\",\"DOI\",\"Authorizer\",\"Statement\",\"CC License\",\"Non-ACM Copyright\"]\n",
    "dfACM['Email2'] = dfACM.EmailX.apply(lambda x: x.split(\" \")[0])\n",
    "dfACM['Signed'] = dfACM['Non-ACM Copyright'].apply(lambda x: x[:-3]) != \"load For\"\n",
    "dfACM[\"TitleOld\"] = dfACM.Title\n",
    "dfACM.Title = dfACM.TitleOld.apply(lambda x: x.split(\" \\\\setcopyright{\")[0])\n",
    "dfACM[\"VenueShort\"] = dfACM.ID.apply(lambda x: re.sub(r'[0-9]', '', x))\n",
    "\n",
    "dfACM[\"TitleRaw\"] = dfACM.Title.str.replace('\"', '')\n",
    "dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace('[', '', regex=False)\n",
    "dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace('`', '', regex=False)\n",
    "dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace('“', '', regex=False)\n",
    "dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace(\"'\", '', regex=False)\n",
    "dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace('(', '', regex=False)\n",
    "dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace('#', '', regex=False)\n",
    "dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.lower()\n",
    "print(dfACM[\"TitleRaw\"].apply(lambda x: x[0]).unique())\n",
    "\n",
    "dictVenue = {'pn':\"Paper\",\n",
    "    'ws':\"Workshops / Symposia\",\n",
    "    'cs':'Case Studies of HCI in Practice',\n",
    "    'crs':'Courses',\n",
    "    'dc':'Doctoral Consortium',\n",
    "    'alt': 'alt.chi',\n",
    "    'sig': 'Special Interest Groups',\n",
    "    'panel': 'Panels',\n",
    "    'sgc': 'Student Game Competition',\n",
    "    'sdc': 'Student Design Competition',\n",
    "    'dein': 'Interactivity',\n",
    "    'int': 'Interactivity',\n",
    "    'src': 'Student Research Competition',\n",
    "    'lbw': 'Late-Breaking Work'}\n",
    "\n",
    "dfACM.VenueShort = dfACM.VenueShort.str.replace(\"dein\", \"int\")\n",
    "\n",
    "dfACM[\"VenueName\"] = dfACM.VenueShort.map(dictVenue)\n",
    "\n",
    "myOrder = CategoricalDtype(\n",
    "    ['pn', 'lbw', 'ws', 'cs', 'alt', 'dein', 'int', 'dc', 'sig', 'panel', 'crs',  'src', 'sdc', 'sgc'], \n",
    "    ordered=True\n",
    ")\n",
    "dfACM.VenueShort = dfACM.VenueShort.astype(myOrder)\n",
    "\n",
    "\n",
    "\n",
    "dfACM = dfACM.drop_duplicates(\"ID\")\n",
    "df = dfACM\n",
    "\n",
    "print(len(df))\n",
    "df = pd.merge(df, dfQ, on=\"ID\")\n",
    "\n",
    "print(len(df))\n",
    "df = pd.merge(df, dfTAPS[[\"ID\", \"PaperID\"]], left_on=\"ID\", right_on=\"ID\")\n",
    "print(len(df))\n",
    "\n",
    "df = df.sort_values([\"SessionName\", \"TitleRaw\"])\n",
    "\n",
    "text = []\n",
    "lastVenueShort = \"\"\n",
    "counter = 1\n",
    "\n",
    "tapsTOC = []\n",
    "\n",
    "lastSessionName = \"\"\n",
    "\n",
    "lstAuthorIndex = []\n",
    "for i, e in df.iterrows():\n",
    "\n",
    "        \n",
    "    if (e.SessionName != lastSessionName):\n",
    "        \n",
    "        if counter != 1:\n",
    "            text.append(f'\\\\end{{enumerate}}')\n",
    "            text.append(\"\")\n",
    "            \n",
    "        temp = e.SessionName.replace(\"&\", \"\\\\&\").replace(\"#\", \"\\\\#\").replace(\"_\", \" \")\n",
    "        \n",
    "        text.append(f'\\\\subsection{{{temp}}}')\n",
    "        text.append(\"\")\n",
    "        text.append(f'\\\\begin{{enumerate}}')\n",
    "        \n",
    "        \n",
    "        lastSessionName = e.SessionName\n",
    "    \n",
    "    TOC_ID = f\"Paper{counter:03}\"\n",
    "    text.append(f'\\\\item[\\\\href{{{e.DOI}}}{{\\\\textbf{{{TOC_ID}}}}}]')\n",
    "    \n",
    "    xx =f'\\\\href{{{e.DOI}}}{{\\\\textbf{{{e.Title}}}}}\\\\\\\\'\n",
    "    text.append(xx.replace(\"&\", \"\\\\&\").replace(\"#\", \"\\\\#\"))\n",
    "    for x in e.Author.split(\";\"):\n",
    "        x = x.split(\":\")\n",
    "        xx = f\"{x[0]} \\\\emph{{({x[1]})}} \\\\\\\\\"\n",
    "        lstAuthorIndex.append([x[0], TOC_ID])\n",
    "        text.append(xx.replace(\"&\", \"\\\\&\").replace(\"#\", \"\\\\#\").replace(\",\", \", \").replace(\"  \", \" \"))\n",
    "    \n",
    "    text.append(\"\")\n",
    "    \n",
    "    tapsTOC.append([counter, e.PaperID, e.ID, TOC_ID, e.Title, e.SessionName])\n",
    "    counter = counter + 1\n",
    "\n",
    "text.append(f'\\\\end{{enumerate}}')\n",
    "\n",
    "if (len(text) > 0):\n",
    "    with open(f'./content/content-paper.tex', 'w') as fp:\n",
    "        fp.write('\\n'.join(text))\n",
    "        \n",
    "        \n",
    "with open('./TOC-CHI23.csv', 'w', newline='') as csvfile:\n",
    "    w = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='\"')\n",
    "    w.writerow([\"ID\",\"PaperID\",\"PCS_ID\",\"TOC_ID\",\"Title\",\"Session\"])\n",
    "    for e in tapsTOC:\n",
    "        w.writerow(e)\n",
    "        \n",
    "dfAI = pd.DataFrame(lstAuthorIndex)\n",
    "dfAI.columns = [\"Name\", \"Submission\"]\n",
    "dfAI = dfAI.groupby(\"Name\").Submission.apply(lambda x: \", \".join(x))\n",
    "dfAI = dfAI.reset_index()\n",
    "dfAI[\"NameRaw\"] = dfAI.Name.str.replace('\"', '')\n",
    "dfAI[\"NameRaw\"] = dfAI.NameRaw.apply(lambda x: unidecode(x))\n",
    "dfAI[\"NameRaw\"] = dfAI.NameRaw.str.replace('[', '', regex=False)\n",
    "dfAI[\"NameRaw\"] = dfAI.NameRaw.str.lower()\n",
    "dfAI = dfAI.sort_values(\"NameRaw\")\n",
    "\n",
    "if (len(dfAI) > 0):\n",
    "    with open(f'./content/index-paper.tex', 'w') as fp:\n",
    "        fp.write('\\\\begin{multicols}{2}\\n')\n",
    "        for i, e in dfAI.iterrows():\n",
    "            fp.write(f'{e.Name} \\dotfill {e.Submission}\\\\\\\\\\n')\n",
    "            \n",
    "        fp.write('\\\\end{multicols}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "romance-frost",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "circular-conditioning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ángel Alexander Cabrera \\\\dotfill Paper419'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{e.Name} \\dotfill {e.Submission}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "induced-beatles",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-sociology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
