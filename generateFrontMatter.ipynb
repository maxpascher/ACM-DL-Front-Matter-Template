{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faced-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import json\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-palmer",
   "metadata": {},
   "source": [
    "# Read Proceedings Information\n",
    "Update the `proceedingsInfo.csv` file according to your conference and the filed downloaded from PCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "radio-stream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>File</th>\n",
       "      <th>NameCommittee</th>\n",
       "      <th>NameReviewers</th>\n",
       "      <th>Prefix</th>\n",
       "      <th>Order</th>\n",
       "      <th>UseQOALASessions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paper</td>\n",
       "      <td>paper</td>\n",
       "      <td>tp23a</td>\n",
       "      <td>Associated Chairs</td>\n",
       "      <td>Reviewers</td>\n",
       "      <td>pn</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Late-Breaking Work</td>\n",
       "      <td>lbw</td>\n",
       "      <td>tp23b</td>\n",
       "      <td>Associated Chairs</td>\n",
       "      <td>Reviewers</td>\n",
       "      <td>lbw</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Demonstration</td>\n",
       "      <td>demo</td>\n",
       "      <td>tp23c</td>\n",
       "      <td>Jury Member</td>\n",
       "      <td>Reviewers</td>\n",
       "      <td>demo</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doctoral Consortium</td>\n",
       "      <td>dc</td>\n",
       "      <td>tp23d</td>\n",
       "      <td>Jury Member</td>\n",
       "      <td>Reviewers</td>\n",
       "      <td>dc</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Workshop</td>\n",
       "      <td>ws</td>\n",
       "      <td>tp23e</td>\n",
       "      <td>Jury Member</td>\n",
       "      <td>Reviewers</td>\n",
       "      <td>ws</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name   Code   File      NameCommittee NameReviewers Prefix  \\\n",
       "0                Paper  paper  tp23a  Associated Chairs     Reviewers     pn   \n",
       "1   Late-Breaking Work    lbw  tp23b  Associated Chairs     Reviewers    lbw   \n",
       "2        Demonstration   demo  tp23c        Jury Member     Reviewers   demo   \n",
       "3  Doctoral Consortium     dc  tp23d        Jury Member     Reviewers     dc   \n",
       "4             Workshop     ws  tp23e        Jury Member     Reviewers     ws   \n",
       "\n",
       "   Order  UseQOALASessions  \n",
       "0      1              True  \n",
       "1      2             False  \n",
       "2      3             False  \n",
       "3      4             False  \n",
       "4      5             False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVenues = pd.read_csv(\"proceedingsInfo.csv\")\n",
    "dfVenues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-mortality",
   "metadata": {},
   "source": [
    "# Generate Committee Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "specific-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCommittee(venueCode):\n",
    "    path = f\"./data-PCS/{venueCode}_committee.csv\"\n",
    "    if (not os.path.isfile(path)):\n",
    "        print(f\"{venueCode} has no committee file\")\n",
    "        return []\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df[\"Reviews assigned\"] != 0]\n",
    "    \n",
    "    if (len(df) == 0):\n",
    "        print(f\"{venueCode} has no reviewers\")\n",
    "        return []\n",
    "\n",
    "    lstText = []\n",
    "    df[\"Family name\"] = df[\"Family name\"].str.title()\n",
    "    df[\"First name\"] = df[\"First name\"].str.title()\n",
    "    #df[\"Middle name\"] = df[\"Middle name\"].str.title()\n",
    "    df = df.sort_values([\"Family name\", \"First name\", \"Middle initial\"])\n",
    "\n",
    "    for i, e in df.iterrows():\n",
    "        for i in range (1,7):\n",
    "            if isinstance(e[f\"Affil {i} Institution\"], str):\n",
    "                break\n",
    "        aff = \"\"\n",
    "        if isinstance(e[f\"Affil {i} Institution\"], str):\n",
    "            aff = f'{e[f\"Affil {i} Institution\"]}, {e[f\"Affil {i} Country\"]}'\n",
    "\n",
    "        aff = aff.replace(\"&\", \"\\\\&\")\n",
    "        if isinstance(e[\"Middle initial\"], str):\n",
    "            lstText.append(f'{e[\"First name\"]} {e[\"Middle initial\"]} {e[\"Family name\"]}, \\\\emph{{{aff}}}\\\\\\\\')\n",
    "        else:\n",
    "            lstText.append(f'{e[\"First name\"]} {e[\"Family name\"]}, \\\\emph{{{aff}}}\\\\\\\\')\n",
    "\n",
    "    if (len(df) > 50):   \n",
    "        lstText.insert(0, \"\\\\begin{multicols}{2}\")\n",
    "        lstText.append(\"\\end{multicols}\")\n",
    "    else:\n",
    "        \n",
    "        lstText.insert(0, \"%\\\\begin{multicols}{2}\")\n",
    "        lstText.append(\"%\\end{multicols}\")\n",
    "    lstText.append(\"\")\n",
    "    return lstText\n",
    "\n",
    "def getReviews(venueCode):\n",
    "    path = f\"./data-PCS/{venueCode}_reviewers.csv\"\n",
    "    if (not os.path.isfile(path)):\n",
    "        print(f\"{venueCode} has no reviwer file\")\n",
    "        return []\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df[\"Reviews assigned\"] != 0]\n",
    "    \n",
    "    if (len(df) == 0):\n",
    "        print(f\"{venueCode} has no reviewers\")\n",
    "        return []\n",
    "    \n",
    "    # Ensure that all names start with a capital first latter.\n",
    "    df[\"Family name\"] = df[\"Family name\"].apply(lambda x: x[0].title()+x[1:] if len(x)>2 else x)\n",
    "    df[\"First name\"] = df[\"First name\"].apply(lambda x: x[0].title()+x[1:] if len(x)>2 else x)\n",
    "    if \"Middle name\"in df.columns:\n",
    "        df[\"Middle name\"] = df[\"Middle name\"].apply(lambda x: x[0].title()+x[1:] if len(x)>2 else x)\n",
    "    \n",
    "    df = df.sort_values([\"Family name\", \"First name\", \"Middle initial\"])\n",
    "    lstText = []\n",
    "    lstText.append(\"\\\\begin{multicols}{3}\")\n",
    "    for i, e in df.iterrows():\n",
    "        if isinstance(e[\"Middle initial\"], str):\n",
    "            lstText.append(f'{e[\"First name\"]} {e[\"Middle initial\"]} {e[\"Family name\"]}\\\\\\\\')\n",
    "        else:\n",
    "            lstText.append(f'{e[\"First name\"]} {e[\"Family name\"]}\\\\\\\\')\n",
    "    lstText.append(\"\\\\end{multicols}\")\n",
    "    lstText.append(\"\")\n",
    "    return lstText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "understood-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp23c has no reviwer file\n",
      "tp23d has no reviwer file\n",
      "tp23e has no reviwer file\n"
     ]
    }
   ],
   "source": [
    "for i, e in dfVenues.iterrows():\n",
    "    lstExport = []\n",
    "    lstExport.append(\"% If this venue/track has subcommittees, you might want to split the \\subsection{Committee Member} into different \\subsubsections for the different committees.\")\n",
    "    lstExport.append(\"\")    \n",
    "    lstExport.append(f\"\\\\subsection{{{e.Name} Chairs}}\")\n",
    "    lstExport.append(\"First Chair Full Name, \\emph{Affiliation, Country}\\\\\\\\\")\n",
    "    lstExport.append(\"Second Chair Full Name, \\emph{Affiliation, Country}\")\n",
    "    lstExport.append(\"\")\n",
    "    lstExport.append(f\"%\\subsection*{{Assistants to {e.Name} Chairs}}\")\n",
    "    lstExport.append(\"%First Assistants Full Name, \\emph{Affiliation}\\\\\\\\\")\n",
    "    lstExport.append(\"%Second Assistants Full Name, \\emph{Affiliation}\")\n",
    "    lstExport.append(\"\")\n",
    "    lstExport.append(\"\")\n",
    "    \n",
    "    commitee = getCommittee(e.File)\n",
    "    if (len(commitee) > 0):\n",
    "        lstExport.append(f\"\\subsection{{{e.NameCommittee}}}\")\n",
    "        lstExport.extend(commitee)\n",
    "\n",
    "    reviewers = getReviews(e.File)\n",
    "    if (len(reviewers) > 0):\n",
    "        lstExport.append(f\"\\subsection{{{e.NameReviewers}}}\")\n",
    "        lstExport.extend(reviewers)\n",
    "    \n",
    "    if (len(lstExport) > 0):\n",
    "        with open(f'committee/committee-{e.Code}.tex', 'w') as fp:\n",
    "            fp.write('\\n'.join(lstExport))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-basics",
   "metadata": {},
   "source": [
    "# Loading ACM E-Rights CSV File\n",
    "To get the CSV, navigate to https://cms.acm.org/cms_proceeding_papers_public.cfm?proceedingID=YOURPROCEEDINGSID&confID=YOURCONFERENCEID, at the top left press the `Create CSV` button and copy-and-pasted the content from the new window into the `export.csv` in the `data-erights` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "royal-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"./data-erights/export.csv\", 'r')\n",
    "lines = file1.readlines()\n",
    "ids = []\n",
    "lstLines = []\n",
    "for x in lines[1:]:\n",
    "    e = x[1:].split('\",\"')\n",
    "\n",
    "    if (not(\"WITHDRAWN\" in x)):\n",
    "        lstLines.append(e)\n",
    "        ids.append(x.split(\",\")[0].replace('\"', \"\"))\n",
    "    else:\n",
    "        print(\"WITHDRAWN\", x.split(\",\")[0].replace('\"', \"\"))\n",
    "    \n",
    "dfACM = pd.DataFrame(lstLines)\n",
    "dfACM.columns = [\"ID\",\"Title\",\"Author\",\"Email\",\"DL Paper Type\",\"Rights Granted\",\"Third Party\",\"Aux. Material\",\"Video Recording\",\"Artistic Images\",\"Govt. Employees\",\"Open Access\",\"DOI\",\"Authorizer\",\"Statement\",\"CC License\",\"Non-ACM Copyright\"]\n",
    "dfACM['Email'] = dfACM.Email.apply(lambda x: x.split(\" \")[0])\n",
    "dfACM['Signed'] = dfACM['Non-ACM Copyright'].apply(lambda x: x[:-3]) != \"load For\"\n",
    "dfACM.Title = dfACM.Title.apply(lambda x: x.split(\" \\\\setcopyright{\")[0])\n",
    "dfACM[\"Prefix\"] = dfACM.ID.apply(lambda x: re.sub(r'[0-9]', '', x))\n",
    "\n",
    "dfACM[\"TitleRaw\"] = dfACM.Title.str.replace('\"', '')\n",
    "dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace('[', '', regex=False)\n",
    "\n",
    "## Might needs to be applied to fix LaTex issues.\n",
    "#dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace('`', '', regex=False)\n",
    "#dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace('“', '', regex=False)\n",
    "#dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace(\"'\", '', regex=False)\n",
    "#dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace('(', '', regex=False)\n",
    "#dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.replace('#', '', regex=False)\n",
    "#dfACM[\"TitleRaw\"] = dfACM.TitleRaw.str.lower()\n",
    "\n",
    "# Remove duplicates, this is possible when the contact authors can not sign the copyright for all authors.\n",
    "dfACM = dfACM.drop_duplicates(\"ID\") \n",
    "\n",
    "dfACM = dfACM[[\"ID\", \"Prefix\", \"Title\", \"Author\", \"DOI\"]]\n",
    "\n",
    "#dfACM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "opponent-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(dfACM, dfVenues[[\"Prefix\", \"Name\", \"Code\"]], on=\"Prefix\")\n",
    "\n",
    "myOrder = CategoricalDtype(\n",
    "    dfVenues.sort_values(\"Order\").Prefix.to_list(), \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "df.Prefix = df.Prefix.astype(myOrder)\n",
    "df = df.sort_values([\"Prefix\", \"Title\"])\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-portuguese",
   "metadata": {},
   "source": [
    "# Load Session Data From QOALA\n",
    "QOALA is the SIGCHI tool to schedule conferences, see https://services.sigchi.org/qoala. Exort the session data from QOALA as `.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "applied-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data-QOALA/export.json\", 'r') as f:\n",
    "    qoala = json.load(f)\n",
    "    \n",
    "if (qoala[\"schemeVersion\"] != 7):\n",
    "    print(\"WARNING: This script was not tested with the QOALA expert scheme version. It might not fully working.\")\n",
    "    \n",
    "dfQPapers = pd.DataFrame(qoala[\"contents\"])\n",
    "\n",
    "if len(dfQPapers) > 0:\n",
    "\n",
    "    dfX = dfQPapers[dfQPapers.sessionIds.apply(lambda x: len(x) > 1)]\n",
    "    if len (dfX) > 0:\n",
    "        print(f'WARNING: The following papers are in more than one session: {dfX.importedId.to_list()}')\n",
    "\n",
    "    dfQPapers.sessionIds = dfQPapers.sessionIds.apply(lambda x: x[0])\n",
    "\n",
    "    dfQSessions = pd.DataFrame(qoala[\"sessions\"])\n",
    "    dfQSessions = dfQSessions.rename(columns={\"id\":\"sessionId\", \"name\":\"SessionName\"})\n",
    "\n",
    "    dfQoala = pd.merge(dfQPapers, dfQSessions[[\"sessionId\", \"SessionName\"]], left_on=\"sessionIds\", right_on=\"sessionId\", how=\"left\")[[\"importedId\", \"title\", \"SessionName\"]]\n",
    "    dfQoala[\"File\"] = dfQoala.importedId.apply(lambda x: x.split(\"-\")[0])\n",
    "    dfQoala[\"IdRaw\"] = dfQoala.importedId.apply(lambda x: x.split(\"-\")[1])\n",
    "\n",
    "    myMap = dfVenues.set_index(\"File\")[\"Prefix\"].to_dict()\n",
    "    dfQoala[\"Prefix\"] = dfQoala.File.map(myMap)\n",
    "\n",
    "    dfQoala[\"ID\"] = dfQoala[\"Prefix\"] + dfQoala[\"IdRaw\"]\n",
    "    dfQoala.head()\n",
    "else:\n",
    "    print(\"WARNING: QOALA data for the papers is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\"SessionName\" in df.columns):\n",
    "    del df[\"SessionName\"]\n",
    "df = pd.merge(df, dfQoala[[\"ID\", \"SessionName\"]], on=\"ID\", how=\"outer\")\n",
    "\n",
    "for i, e in dfVenues.iterrows():\n",
    "    if (not e.UseQOALASessions):\n",
    "        df.loc[df.Prefix == e.Prefix, \"SessionName\"] = e.Name\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-passion",
   "metadata": {},
   "source": [
    "# Generate the TOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "flush-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstExport = []\n",
    "lstExport.append(\"%% This file lists all items that are in the proceedings in the ACM DL. This again varies depending on if you have a companion proceedings or not.\")\n",
    "lstExport.append(\"%% Note: For conferences that will publish the full papers in PACMHCI, then the full papers are not to be listed here.\")\n",
    "lstExport.append(\"\")\n",
    "lastPrefix = \"\"\n",
    "counterTOC = 1\n",
    "\n",
    "tapsTOC=[]\n",
    "lstAuthorIndex = []\n",
    "lstDetails = []\n",
    "for j, f in dfVenues.sort_values(\"Order\").iterrows():\n",
    "    dfTrack = df[df.Prefix == f.Prefix]\n",
    "    \n",
    "    counter = 1\n",
    "    lastSessionName = \"\"\n",
    "    \n",
    "    lstExport.append(f'\\\\subsection{{{f.Name}}}')\n",
    "    \n",
    "    if (f.UseQOALASessions):\n",
    "        dfTrack = dfTrack.sort_values([\"SessionName\", \"Name\"])\n",
    "    else: \n",
    "        dfTrack = dfTrack.sort_values([\"Name\"])\n",
    "    \n",
    "    for i, e in dfTrack.iterrows():\n",
    "        \n",
    "        if (lastSessionName != e.SessionName) & (f.UseQOALASessions):\n",
    "            lastSessionName = e.SessionName\n",
    "            if (counter != 1):\n",
    "                lstExport.pop()\n",
    "                lstExport.append(f'\\\\end{{enumerate}}')\n",
    "                lstExport.append(\"\")\n",
    "            lstExport.append(f'\\\\subsubsection{{{e.SessionName}}}')\n",
    "            lstExport.append(f'\\\\begin{{enumerate}}')\n",
    "        elif (counter == 1):\n",
    "            lstExport.append(f'\\\\begin{{enumerate}}')\n",
    "        \n",
    "        lstExport.append(f'%PCS ID: {e.ID}')\n",
    "        TOC_ID = f\"{e.Code.upper()}{counter:03}\"\n",
    "        lstExport.append(f'\\\\item[\\\\href{{{e.DOI}}}{{\\\\textbf{{{TOC_ID}}}}}]')\n",
    "\n",
    "        xx = f'\\\\href{{{e.DOI}}}{{\\\\textbf{{{e.Title}}}}}\\\\\\\\'\n",
    "        lstExport.append(xx.replace(\"&\", \"\\\\&\").replace(\"#\", \"\\\\#\"))\n",
    "        for x in e.Author.split(\";\"):\n",
    "            x = x.split(\":\")\n",
    "            xx = f\"{x[0]}, \\\\emph{{({x[1]})}}\\\\\\\\\"\n",
    "            lstAuthorIndex.append([x[0], TOC_ID])\n",
    "            lstExport.append(xx.replace(\"&\", \"\\\\&\").replace(\"#\", \"\\\\#\").replace(\",\", \", \").replace(\"  \", \" \"))\n",
    "\n",
    "        lstExport.append(\"\")\n",
    "\n",
    "        counter = counter + 1\n",
    "        counterTOC = counterTOC + 1\n",
    "\n",
    "        lstDetails.append({\"ID\": e.ID, \"TOC_ID\":TOC_ID, \"Order\":counterTOC})\n",
    "    \n",
    "    lstExport.pop()\n",
    "    lstExport.append(f'\\\\end{{enumerate}}')\n",
    "    lstExport.append(\"\")\n",
    "    lstExport.append(\"\")\n",
    "\n",
    "if (len(lstExport) > 0):\n",
    "    with open(f'./content/content.tex', 'w') as fp:\n",
    "        fp.write('\\n'.join(lstExport))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-cradle",
   "metadata": {},
   "source": [
    "# Generate the TOC for APTARA\n",
    "This puts the TOC entries into \"sessions.\" Sessions are the structure ACM used in the ACM DL; for example, see the structure here on the left side: https://dl.acm.org/doi/proceedings/10.1145/3544548\n",
    "The list is to be sent via email to APTARA so they can sort them accordingly and prepare for the ACM upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intensive-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAptaraExport = pd.merge(df, pd.DataFrame(lstDetails), on=\"ID\")\n",
    "dfAptaraExport = dfAptaraExport.rename(columns={\"Name\": \"SessionName\"})\n",
    "dfAptaraExport = dfAptaraExport[[\"Order\", \"ID\", \"TOC_ID\", \"Title\", \"SessionName\"]]\n",
    "dfAptaraExport.head()\n",
    "dfAptaraExport.to_csv(\"./export/TOC-for-APTARA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-tumor",
   "metadata": {},
   "source": [
    "# Generate Author Index for the Back Matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efficient-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAI = pd.DataFrame(lstAuthorIndex)\n",
    "dfAI.columns = [\"Name\", \"Submission\"]\n",
    "dfAI = dfAI.groupby(\"Name\").Submission.apply(lambda x: \", \".join(x))\n",
    "dfAI = dfAI.reset_index()\n",
    "dfAI[\"NameRaw\"] = dfAI.Name.str.replace('\"', '')\n",
    "dfAI[\"NameRaw\"] = dfAI.NameRaw.apply(lambda x: unidecode(x))\n",
    "dfAI[\"NameRaw\"] = dfAI.NameRaw.str.replace('[', '', regex=False)\n",
    "dfAI[\"NameRaw\"] = dfAI.NameRaw.str.lower()\n",
    "dfAI = dfAI.sort_values(\"NameRaw\")\n",
    "\n",
    "with open(f'./content/index.tex', 'w') as fp:\n",
    "    fp.write('\\\\begin{multicols}{2}\\n')\n",
    "    for i, e in dfAI.iterrows():\n",
    "        fp.write(f'{e.Name} \\dotfill {e.Submission}\\\\\\\\\\n')\n",
    "\n",
    "    fp.write('\\\\end{multicols}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
